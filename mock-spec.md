## openwebuiから呼び出せるLLMモック

#　概要
open webuiから使える様にollama-apiに対応したモックアップを'ollama-mock.py'として作成する。

chatなどで生成依頼が来たら、ダミーの応答を1秒毎に繰り返し、10回繰り返したら終了。
ダミーの応答は下記とする。
```
この応答はダミーの応答です。10回繰り返したら終わり。
適当な長さの応答があれば良い。
```

apiについて全部実装してください。
実装はpythonで実装してください。
